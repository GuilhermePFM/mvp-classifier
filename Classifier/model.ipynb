{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d7b70e9",
   "metadata": {},
   "source": [
    "# Classifier model for personal spendings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07dfcc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1b2709",
   "metadata": {},
   "source": [
    "## Set Env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c90dbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "root_dir = Path('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ffde7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e023de8",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5690afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import load_treated_dataset\n",
    "\n",
    "complete_dataset = load_treated_dataset(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac568d4",
   "metadata": {},
   "source": [
    "## Split test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c38f6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training import split_train_test\n",
    "train, test = split_train_test(complete_dataset, test_size=test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd505f08",
   "metadata": {},
   "source": [
    "## Build Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072de780",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from preprocess import get_preprocessing_transformer\n",
    "\n",
    "\n",
    "clf = Pipeline(\n",
    "    steps=[(\"preprocessor\", get_preprocessing_transformer()), (\"classifier\", LogisticRegression())],\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c347a25e",
   "metadata": {},
   "source": [
    "### Encode y classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a83d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train =train['categoria']\n",
    "y_enconder = LabelEncoder().fit(y_train)\n",
    "y_train_encoded = y_enconder.transform(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dc412f",
   "metadata": {},
   "source": [
    "### Fit Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e78299",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= train[[i for i in train.columns if i!='categoria']]\n",
    "\n",
    "clf.fit(X_train, y_train_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b0f852",
   "metadata": {},
   "source": [
    "# Validate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a1387f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test[[i for i in train.columns if i!='categoria']]\n",
    "y_test = test['categoria']\n",
    "y_test_encoded = y_enconder.transform(y_test)\n",
    "print(\"model score: %.3f\" % clf.score(X_test, y_test_encoded))\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec49124",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Create the model\n",
    "gbm = GradientBoostingClassifier(\n",
    "    n_estimators=100,    # Number of boosting stages\n",
    "    learning_rate=0.1,   # Step size shrinkage\n",
    "    max_depth=3,         # Maximum depth of each tree\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "gbm.fit(preprocessed_data[[i for i in preprocessed_data if i!=TARGET]].fillna(0), preprocessed_data[TARGET])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "048b168c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guilh\\AppData\\Local\\Temp\\ipykernel_23016\\1463220249.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[TEXT_FEATURE] = X_test[TEXT_FEATURE].fillna(\"\")\n",
      "Map: 100%|██████████| 172/172 [00:00<00:00, 8309.38 examples/s]\n",
      "Map: 100%|██████████| 172/172 [00:04<00:00, 42.24 examples/s]\n"
     ]
    }
   ],
   "source": [
    "X_test[TEXT_FEATURE] = X_test[TEXT_FEATURE].fillna(\"\")\n",
    "tokenized_df = tokenized_pytorch_tensors(\n",
    "    X_test[[TEXT_FEATURE]],\n",
    "    column_list=[\"input_ids\", \"attention_mask\"]\n",
    ")\n",
    "preprocessed_num_cat_features_df = column_transformer.fit_transform(\n",
    "    X_test[[*NUMERICAL_FEATURE, *CATEGORICAL_FEATURE]]\n",
    ")\n",
    "hidden_states_df = hidden_state_from_text_inputs(tokenized_df)\n",
    "y_test_encoded = classification_encoder.transform(y_test)\n",
    "\n",
    "preprocessed_data = pd.concat(\n",
    "    [\n",
    "        preprocessed_num_cat_features_df.reset_index(drop=True),\n",
    "        hidden_states_df.reset_index(drop=True),\n",
    "        pd.DataFrame(y_test_encoded).reset_index(drop=True)\n",
    "    ],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "preprocessed_data.rename(columns={0: TARGET}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "57f50763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_pred = gbm.predict(preprocessed_data[[i for i in preprocessed_data if i!=TARGET]])\n",
    "y_test = preprocessed_data[TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c62bb49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6104651162790697\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82952e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# multilabel_confusion_matrix(y_test, y_pred)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b747caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "389727d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ec93e6",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bf70da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "X_train = preprocessed_data[[i for i in preprocessed_data if i!=TARGET]].fillna(0)\n",
    "y_train = preprocessed_data[TARGET]\n",
    "\n",
    "\n",
    "clf = RidgeClassifier(tol=1e-2, solver=\"sparse_cg\")\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c3eaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FITTING THE CLASSIFICATION MODEL using Logistic Regression(tf-idf)\n",
    "lr_tfidf=LogisticRegression(solver = 'liblinear', C=10, penalty = 'l2')\n",
    "lr_tfidf.fit(X_train_vectors_tfidf, y_train)  \n",
    "#Predict y value for test dataset\n",
    "y_predict = lr_tfidf.predict(X_test_vectors_tfidf)\n",
    "y_prob = lr_tfidf.predict_proba(X_test_vectors_tfidf)[:,1]\n",
    "print(classification_report(y_test,y_predict))\n",
    "print('Confusion Matrix:',confusion_matrix(y_test, y_predict))\n",
    " \n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('AUC:', roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6012562d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FITTING THE CLASSIFICATION MODEL using Naive Bayes(tf-idf)\n",
    "nb_tfidf = MultinomialNB()\n",
    "nb_tfidf.fit(X_train_vectors_tfidf, y_train)  \n",
    "#Predict y value for test dataset\n",
    "y_predict = nb_tfidf.predict(X_test_vectors_tfidf)\n",
    "y_prob = nb_tfidf.predict_proba(X_test_vectors_tfidf)[:,1]\n",
    "print(classification_report(y_test,y_predict))\n",
    "print('Confusion Matrix:',confusion_matrix(y_test, y_predict))\n",
    " \n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('AUC:', roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da9613b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-processing the new dataset\n",
    "df_test['clean_text'] = df_test['text'].apply(lambda x: finalpreprocess(x)) #preprocess the data\n",
    "X_test=df_test['clean_text'] \n",
    "#converting words to numerical data using tf-idf\n",
    "X_vector=tfidf_vectorizer.transform(X_test)\n",
    "#use the best model to predict 'target' value for the new dataset \n",
    "y_predict = lr_tfidf.predict(X_vector)      \n",
    "y_prob = lr_tfidf.predict_proba(X_vector)[:,1]\n",
    "df_test['predict_prob']= y_prob\n",
    "df_test['target']= y_predict\n",
    "final=df_test[['clean_text','target']].reset_index(drop=True)\n",
    "print(final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaa4eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_predict))\n",
    "print('Confusion Matrix:',confusion_matrix(y_test, y_predict))\n",
    " \n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('AUC:', roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9212dd9c",
   "metadata": {},
   "source": [
    "# Test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
